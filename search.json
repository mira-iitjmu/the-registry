[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "MIRA Data Catalog Blog",
    "section": "",
    "text": "Welcome to the MIRA Data Catalog & Resources blog! Here we share insights, research findings, and best practices related to AI/ML datasets, evaluation methodologies, and ethical considerations in data science.",
    "crumbs": [
      "Datasets",
      "Blog"
    ]
  },
  {
    "objectID": "blog.html#topics-we-cover",
    "href": "blog.html#topics-we-cover",
    "title": "MIRA Data Catalog Blog",
    "section": "Topics We Cover",
    "text": "Topics We Cover\n\nDataset Creation: Best practices for data collection and annotation\nEvaluation Methods: Benchmarking and assessment techniques\n\nEthical AI: Responsible data practices and bias mitigation\nMultilingual NLP: Challenges and solutions for diverse languages\nResearch Insights: Latest findings from the AI/ML community",
    "crumbs": [
      "Datasets",
      "Blog"
    ]
  },
  {
    "objectID": "blog.html#stay-updated",
    "href": "blog.html#stay-updated",
    "title": "MIRA Data Catalog Blog",
    "section": "Stay Updated",
    "text": "Stay Updated\nFollow our blog for the latest insights on dataset development, evaluation methodologies, and ethical considerations in AI research. We regularly publish articles from our research team and guest contributors.",
    "crumbs": [
      "Datasets",
      "Blog"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Registries",
    "section": "",
    "text": "Browse all datasets. Use the sidebar to jump between pages, or filter the grid above.\n\n\n\n\n\n\n\n\n\n\n\nArchitecture Registry\n\n\nOverview of model architectures organized by category including language models, multimodal models, and specialized architectures\n\n\n\n\n\n\n\n\n\n\nDataset Registry\n\n\nComprehensive collection of datasets for AI/ML research and development\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "architectures/multimodal/index.html",
    "href": "architectures/multimodal/index.html",
    "title": "Multimodal Models",
    "section": "",
    "text": "No matching items",
    "crumbs": [
      "Datasets",
      "Architectures",
      "Multimodal"
    ]
  },
  {
    "objectID": "architectures/specialized/index.html",
    "href": "architectures/specialized/index.html",
    "title": "Specialized Architectures",
    "section": "",
    "text": "No matching items",
    "crumbs": [
      "Datasets",
      "Architectures",
      "Specialized"
    ]
  },
  {
    "objectID": "datasets/index.html",
    "href": "datasets/index.html",
    "title": "Dataset Registry",
    "section": "",
    "text": "Benchmark Datasets\n\n\nStandardized benchmark datasets for evaluating model performance across various NLP tasks\n\n\n\n\n\n\n\n\n\n\nIndic Language Datasets\n\n\nDatasets for Indian languages including translation, RAG, alignment, and paraphrase tasks\n\n\n\n\n\n\n\n\n\n\nSpecialized Datasets\n\n\nDomain-specific and specialized datasets for code generation, scientific literature, and other specialized applications\n\n\n\n\n\n\n\n\n\n\nWeb & Crawled Datasets\n\n\nLarge-scale datasets crawled from the web including general text, multilingual content, and domain-specific collections\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "datasets/indic/index.html",
    "href": "datasets/indic/index.html",
    "title": "Indic Language Datasets",
    "section": "",
    "text": "Bharat Parallel Corpus Collection (BPCC)\n\n\n\n\n\n\n\n\n\n\n\n\n\nai4bharat/Indic-Rag-Suite\n\n\n\n\n\n\n\n\n\n\n\n\n\nai4bharat/IndicParaphrase\n\n\n\n\n\n\n\n\n\n\n\n\n\nai4bharat/Pralekha\n\n\n\n\n\n\n\n\n\n\n\n\n\nai4bharat/indic-align\n\n\n\n\n\n\n\n\n\n\n\n\n\nai4bharat/sangraha\n\n\n\n\n\n\n\n\n\n\n\n\n\nai4bharat/wiki-translate\n\n\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Datasets",
      "Indic Languages"
    ]
  },
  {
    "objectID": "datasets/indic/ai4bharatindic-align.html",
    "href": "datasets/indic/ai4bharatindic-align.html",
    "title": "ai4bharat/indic-align",
    "section": "",
    "text": "The ai4bharat/indic-align dataset represents a comprehensive collection of instruction-following and response alignment data specifically designed for Indic languages. This dataset addresses the critical need for high-quality training data that can help language models better understand and respond to instructions across multiple Indian languages.\n\n\nThis dataset encompasses 11+ Indic languages, providing a rich multilingual resource for researchers and practitioners working on instruction-following tasks in the Indian linguistic context. The primary focus is on creating well-aligned instruction-response pairs that can improve the performance of language models when handling queries and commands in various Indic languages.\n\n\n\n\nMultilingual Coverage: Supports 11+ Indic languages, ensuring broad linguistic representation\nInstruction-Following Focus: Specifically designed for training models to follow instructions accurately\nResponse Alignment: Contains carefully curated instruction-response pairs for optimal model training\nResearch-Backed: Developed by AI4Bharat with accompanying research paper\n\n\n\n\nThe dataset is readily available through Hugging Face, making it easily accessible to the research community. For detailed technical information and methodology, refer to the accompanying research paper: AI4Bharat Indic Align.\nThis dataset is particularly valuable for:\n\nTraining instruction-following models for Indic languages\nImproving response quality and alignment in multilingual settings\nAdvancing research in Indian language processing\nBuilding more inclusive and linguistically diverse AI systems\n\n\n\n\nExplore the dataset interactively using the official Hugging Face dataset viewer:\n🔗 View Dataset on Hugging Face\nQuick Preview: The dataset contains instruction-response pairs in a conversational format. Each record includes an id, interactions (list of instruction-response pairs), and num_turns (conversation length).\nDataset Structure: Each record contains:\n\nid: Unique identifier for the conversation\ninteractions: List of instruction-response pairs\nnum_turns: Number of conversation turns\n\nAvailable Configurations: The dataset includes multiple configurations:\n\nAnudesh: Instruction-following conversations\nDolly_T: Translated Dolly dataset\nOpenAssistant_T: Translated OpenAssistant conversations\nWikiHow: Translated WikiHow articles\nIndoWordNet: WordNet translations\nWiki_Conv: Wikipedia conversation data\nWiki_Chat: Wikipedia chat data\nHHRLHF_T: Human feedback data\nToxic_Matrix: Toxic content alignment data\n\nFor interactive exploration, visit the full dataset page on Hugging Face."
  },
  {
    "objectID": "datasets/indic/ai4bharatindic-align.html#overview",
    "href": "datasets/indic/ai4bharatindic-align.html#overview",
    "title": "ai4bharat/indic-align",
    "section": "",
    "text": "The ai4bharat/indic-align dataset represents a comprehensive collection of instruction-following and response alignment data specifically designed for Indic languages. This dataset addresses the critical need for high-quality training data that can help language models better understand and respond to instructions across multiple Indian languages.\n\n\nThis dataset encompasses 11+ Indic languages, providing a rich multilingual resource for researchers and practitioners working on instruction-following tasks in the Indian linguistic context. The primary focus is on creating well-aligned instruction-response pairs that can improve the performance of language models when handling queries and commands in various Indic languages.\n\n\n\n\nMultilingual Coverage: Supports 11+ Indic languages, ensuring broad linguistic representation\nInstruction-Following Focus: Specifically designed for training models to follow instructions accurately\nResponse Alignment: Contains carefully curated instruction-response pairs for optimal model training\nResearch-Backed: Developed by AI4Bharat with accompanying research paper\n\n\n\n\nThe dataset is readily available through Hugging Face, making it easily accessible to the research community. For detailed technical information and methodology, refer to the accompanying research paper: AI4Bharat Indic Align.\nThis dataset is particularly valuable for:\n\nTraining instruction-following models for Indic languages\nImproving response quality and alignment in multilingual settings\nAdvancing research in Indian language processing\nBuilding more inclusive and linguistically diverse AI systems\n\n\n\n\nExplore the dataset interactively using the official Hugging Face dataset viewer:\n🔗 View Dataset on Hugging Face\nQuick Preview: The dataset contains instruction-response pairs in a conversational format. Each record includes an id, interactions (list of instruction-response pairs), and num_turns (conversation length).\nDataset Structure: Each record contains:\n\nid: Unique identifier for the conversation\ninteractions: List of instruction-response pairs\nnum_turns: Number of conversation turns\n\nAvailable Configurations: The dataset includes multiple configurations:\n\nAnudesh: Instruction-following conversations\nDolly_T: Translated Dolly dataset\nOpenAssistant_T: Translated OpenAssistant conversations\nWikiHow: Translated WikiHow articles\nIndoWordNet: WordNet translations\nWiki_Conv: Wikipedia conversation data\nWiki_Chat: Wikipedia chat data\nHHRLHF_T: Human feedback data\nToxic_Matrix: Toxic content alignment data\n\nFor interactive exploration, visit the full dataset page on Hugging Face."
  },
  {
    "objectID": "posts/ipynb-direct-test/index.html",
    "href": "posts/ipynb-direct-test/index.html",
    "title": "Direct Jupyter Notebook Blog Post",
    "section": "",
    "text": "This blog post tests whether Quarto can use .ipynb files directly as blog posts without converting them to .qmd files.\n\n\nWe’re testing the direct integration of Jupyter notebooks into the Quarto blog system. This approach allows us to use notebooks as-is without any conversion.\n\n\n        \n        \n        \n\n\nLibraries imported successfully!\nNumPy version: 2.3.4\nPandas version: 2.3.3\nMatplotlib version: 3.10.7\nPlotly version: 6.3.1\nPlotly renderer: plotly_mimetype+notebook_connected\n\n\n\n\n\nLet’s create some visualizations to test the notebook functionality:\n\n\n\n\n\n\n\n\n\n\n\n\nNow let’s test interactive plots with Plotly:\n\n\nCreating static plots with matplotlib...\n\n\n\n\n\n\n\n\n\n\nTrying Plotly with different renderers...\nCurrent renderer: browser\nPlotly plot displayed successfully!\n\n\n\n\n\nLet’s perform some data analysis to test the full functionality:\n\n\nDataset Overview:\nShape: (1000, 4)\nColumns: ['feature1', 'feature2', 'feature3', 'category']\n\nBasic Statistics:\n          feature1     feature2     feature3\ncount  1000.000000  1000.000000  1000.000000\nmean     99.406538    50.083892    25.051765\nstd      15.019325     9.584889     4.909747\nmin      51.534175    11.986218     9.665062\n25%      89.731651    43.610755    21.780566\n50%      99.382217    50.484554    25.221117\n75%     110.032986    56.538834    28.235850\nmax     153.573688    78.507077    38.959856\n\nCorrelation Matrix:\n          feature1  feature2  feature3\nfeature1  1.000000 -0.031283 -0.032409\nfeature2 -0.031283  1.000000 -0.013392\nfeature3 -0.032409 -0.013392  1.000000\n\nGroup Statistics by Category:\n           feature1              feature2             feature3          \n               mean        std       mean       std       mean       std\ncategory                                                                \nType A    99.841366  14.007879  49.861579  9.696586  25.474744  5.014962\nType B    98.676123  15.753299  49.897279  9.559018  24.580827  4.839809\nType C    99.731265  15.167006  50.460367  9.526801  25.135579  4.858440\n\n\n\n\n\nThis notebook demonstrates that Quarto can handle .ipynb files directly as blog posts. The key features tested include:\n\n✅ YAML metadata in the first cell\n✅ Mixed content (markdown and code cells)\n✅ Python code execution with multiple libraries\n✅ Static plots with matplotlib\n✅ Interactive plots with Plotly\n✅ Data analysis with pandas and numpy\n✅ Proper formatting and output display\n\nThis approach allows data scientists to use their existing Jupyter notebooks directly in Quarto blogs without any conversion!\n\n\n=== Jupyter Notebook Test Results ===\n✅ NumPy: 2.3.4\n✅ Pandas: 2.3.3\n✅ Matplotlib: 3.10.7\n✅ Plotly: 6.3.1\n\n\n\n\n\n\n\n\n\n✅ Matplotlib plots working!\n✅ Notebook execution successful!"
  },
  {
    "objectID": "posts/ipynb-direct-test/index.html#introduction",
    "href": "posts/ipynb-direct-test/index.html#introduction",
    "title": "Direct Jupyter Notebook Blog Post",
    "section": "",
    "text": "We’re testing the direct integration of Jupyter notebooks into the Quarto blog system. This approach allows us to use notebooks as-is without any conversion.\n\n\n        \n        \n        \n\n\nLibraries imported successfully!\nNumPy version: 2.3.4\nPandas version: 2.3.3\nMatplotlib version: 3.10.7\nPlotly version: 6.3.1\nPlotly renderer: plotly_mimetype+notebook_connected"
  },
  {
    "objectID": "posts/ipynb-direct-test/index.html#data-visualization-test",
    "href": "posts/ipynb-direct-test/index.html#data-visualization-test",
    "title": "Direct Jupyter Notebook Blog Post",
    "section": "",
    "text": "Let’s create some visualizations to test the notebook functionality:"
  },
  {
    "objectID": "posts/ipynb-direct-test/index.html#interactive-plotly-visualization",
    "href": "posts/ipynb-direct-test/index.html#interactive-plotly-visualization",
    "title": "Direct Jupyter Notebook Blog Post",
    "section": "",
    "text": "Now let’s test interactive plots with Plotly:\n\n\nCreating static plots with matplotlib...\n\n\n\n\n\n\n\n\n\n\nTrying Plotly with different renderers...\nCurrent renderer: browser\nPlotly plot displayed successfully!"
  },
  {
    "objectID": "posts/ipynb-direct-test/index.html#data-analysis",
    "href": "posts/ipynb-direct-test/index.html#data-analysis",
    "title": "Direct Jupyter Notebook Blog Post",
    "section": "",
    "text": "Let’s perform some data analysis to test the full functionality:\n\n\nDataset Overview:\nShape: (1000, 4)\nColumns: ['feature1', 'feature2', 'feature3', 'category']\n\nBasic Statistics:\n          feature1     feature2     feature3\ncount  1000.000000  1000.000000  1000.000000\nmean     99.406538    50.083892    25.051765\nstd      15.019325     9.584889     4.909747\nmin      51.534175    11.986218     9.665062\n25%      89.731651    43.610755    21.780566\n50%      99.382217    50.484554    25.221117\n75%     110.032986    56.538834    28.235850\nmax     153.573688    78.507077    38.959856\n\nCorrelation Matrix:\n          feature1  feature2  feature3\nfeature1  1.000000 -0.031283 -0.032409\nfeature2 -0.031283  1.000000 -0.013392\nfeature3 -0.032409 -0.013392  1.000000\n\nGroup Statistics by Category:\n           feature1              feature2             feature3          \n               mean        std       mean       std       mean       std\ncategory                                                                \nType A    99.841366  14.007879  49.861579  9.696586  25.474744  5.014962\nType B    98.676123  15.753299  49.897279  9.559018  24.580827  4.839809\nType C    99.731265  15.167006  50.460367  9.526801  25.135579  4.858440"
  },
  {
    "objectID": "posts/ipynb-direct-test/index.html#conclusion",
    "href": "posts/ipynb-direct-test/index.html#conclusion",
    "title": "Direct Jupyter Notebook Blog Post",
    "section": "",
    "text": "This notebook demonstrates that Quarto can handle .ipynb files directly as blog posts. The key features tested include:\n\n✅ YAML metadata in the first cell\n✅ Mixed content (markdown and code cells)\n✅ Python code execution with multiple libraries\n✅ Static plots with matplotlib\n✅ Interactive plots with Plotly\n✅ Data analysis with pandas and numpy\n✅ Proper formatting and output display\n\nThis approach allows data scientists to use their existing Jupyter notebooks directly in Quarto blogs without any conversion!\n\n\n=== Jupyter Notebook Test Results ===\n✅ NumPy: 2.3.4\n✅ Pandas: 2.3.3\n✅ Matplotlib: 3.10.7\n✅ Plotly: 6.3.1\n\n\n\n\n\n\n\n\n\n✅ Matplotlib plots working!\n✅ Notebook execution successful!"
  },
  {
    "objectID": "contributing.html",
    "href": "contributing.html",
    "title": "Contributing to MIRA Data Catalog",
    "section": "",
    "text": "We welcome contributions to the MIRA Data Catalog! This guide will help you understand how to contribute datasets, architectures, and other content to our growing collection.\n\n\n\n\nTo contribute a new dataset:\n\nChoose the appropriate category for your dataset:\n\nIndic Languages (datasets/indic/) - For Indian language datasets\nWeb & Crawled (datasets/web/) - For web-scraped datasets\nBenchmarks (datasets/benchmarks/) - For evaluation datasets\nSpecialized (datasets/specialized/) - For domain-specific datasets\n\nCreate your dataset file directly in the appropriate category directory:\n\nFor Indic: Create .qmd files directly in datasets/indic/\nFor Web: Create .qmd files directly in datasets/web/\nFor Benchmarks: Create .qmd files directly in datasets/benchmarks/\nFor Specialized: Create .qmd files directly in datasets/specialized/\n\nCreate a .qmd file in the appropriate subcategory directory with the following structure:\n\n---\ntitle: \"Your Dataset Name\"\ndescription: \"Brief description of the dataset\"\ndate: \"YYYY-MM-DD\"\nauthor: \"Your Name\"\ncategories: [\"Category1\", \"Category2\"]\n---\n\n# Your Dataset Name\n\n## Overview\nDetailed description of your dataset.\n\n## Key Features\n- Feature 1\n- Feature 2\n- Feature 3\n\n## Usage\nHow to use this dataset.\n\n## Citation\nIf applicable, include citation information.\n\n\n\nTo contribute a new architecture:\n\nChoose the appropriate category:\n\nLanguage Models (architectures/language-models/) - For language model architectures\nMultimodal (architectures/multimodal/) - For multimodal architectures\nSpecialized (architectures/specialized/) - For specialized architectures\n\nCreate your architecture file directly in the appropriate category directory:\n\nFor Language Models: Create .qmd files directly in architectures/language-models/\nFor Multimodal: Create .qmd files directly in architectures/multimodal/\nFor Specialized: Create .qmd files directly in architectures/specialized/\n\nCreate a .qmd file with similar structure to datasets.\n\n\n\n\nTo contribute a blog post:\n\nCreate a new directory in posts/ with a descriptive name\nAdd an index.qmd file with your blog post content\nInclude proper YAML frontmatter:\n\n---\ntitle: \"Your Blog Post Title\"\ndescription: \"Brief description of the blog post\"\ndate: \"YYYY-MM-DD\"\nauthor: \"Your Name\"\ncategories: [\"Research\", \"AI/ML\"]\n---\n\n\n\n\n\n\nWhen contributing datasets, please include:\n\nClear description of what the dataset contains\nSize and scale information\nLanguage(s) covered\nTask(s) the dataset is designed for\nQuality metrics if available\nUsage examples or code snippets\nCitation information if applicable\nLicense information\n\n\n\n\nWhen contributing architectures, please include:\n\nArchitecture overview and key components\nModel size and parameters\nTraining details if applicable\nPerformance metrics if available\nUse cases and applications\nImplementation details\nCitation information\n\n\n\n\nFor blog posts, please ensure:\n\nClear, engaging writing\nTechnical accuracy\nProper citations and references\nCode examples where relevant\nVisual elements (plots, diagrams) when helpful\nConsistent formatting\n\n\n\n\n\n\n\n\nDataset files: Use descriptive names like dataset-name.qmd\nArchitecture files: Use descriptive names like architecture-name.qmd\nBlog posts: Use descriptive directory names like post-title/\n\n\n\n\ndatasets/\n├── indic/\n│   ├── your-indic-dataset.qmd\n│   └── another-indic-dataset.qmd\n├── web/\n│   └── your-web-dataset.qmd\n├── benchmarks/\n│   └── your-benchmark-dataset.qmd\n└── specialized/\n    └── your-specialized-dataset.qmd\n\narchitectures/\n├── language-models/\n│   └── your-language-model.qmd\n├── multimodal/\n│   └── your-multimodal-model.qmd\n└── specialized/\n    └── your-specialized-architecture.qmd\n\nposts/\n└── your-blog-post/\n    └── index.qmd\n\n\n\n\n\nSubmit your contribution by creating the appropriate files\nOur team will review the content for:\n\nTechnical accuracy\nCompleteness of documentation\nAdherence to guidelines\nQuality and usefulness\n\nFeedback will be provided if revisions are needed\nApproved contributions will be integrated into the catalog\n\n\n\n\nIf you have questions about contributing, please:\n\nCheck existing content for examples\nReview the file structure to understand organization\nContact the maintainers if you need clarification\n\n\n\n\nWe appreciate your contributions to the MIRA Data Catalog. Your efforts help build a comprehensive resource for the AI/ML community!"
  },
  {
    "objectID": "contributing.html#how-to-contribute",
    "href": "contributing.html#how-to-contribute",
    "title": "Contributing to MIRA Data Catalog",
    "section": "",
    "text": "To contribute a new dataset:\n\nChoose the appropriate category for your dataset:\n\nIndic Languages (datasets/indic/) - For Indian language datasets\nWeb & Crawled (datasets/web/) - For web-scraped datasets\nBenchmarks (datasets/benchmarks/) - For evaluation datasets\nSpecialized (datasets/specialized/) - For domain-specific datasets\n\nCreate your dataset file directly in the appropriate category directory:\n\nFor Indic: Create .qmd files directly in datasets/indic/\nFor Web: Create .qmd files directly in datasets/web/\nFor Benchmarks: Create .qmd files directly in datasets/benchmarks/\nFor Specialized: Create .qmd files directly in datasets/specialized/\n\nCreate a .qmd file in the appropriate subcategory directory with the following structure:\n\n---\ntitle: \"Your Dataset Name\"\ndescription: \"Brief description of the dataset\"\ndate: \"YYYY-MM-DD\"\nauthor: \"Your Name\"\ncategories: [\"Category1\", \"Category2\"]\n---\n\n# Your Dataset Name\n\n## Overview\nDetailed description of your dataset.\n\n## Key Features\n- Feature 1\n- Feature 2\n- Feature 3\n\n## Usage\nHow to use this dataset.\n\n## Citation\nIf applicable, include citation information.\n\n\n\nTo contribute a new architecture:\n\nChoose the appropriate category:\n\nLanguage Models (architectures/language-models/) - For language model architectures\nMultimodal (architectures/multimodal/) - For multimodal architectures\nSpecialized (architectures/specialized/) - For specialized architectures\n\nCreate your architecture file directly in the appropriate category directory:\n\nFor Language Models: Create .qmd files directly in architectures/language-models/\nFor Multimodal: Create .qmd files directly in architectures/multimodal/\nFor Specialized: Create .qmd files directly in architectures/specialized/\n\nCreate a .qmd file with similar structure to datasets.\n\n\n\n\nTo contribute a blog post:\n\nCreate a new directory in posts/ with a descriptive name\nAdd an index.qmd file with your blog post content\nInclude proper YAML frontmatter:\n\n---\ntitle: \"Your Blog Post Title\"\ndescription: \"Brief description of the blog post\"\ndate: \"YYYY-MM-DD\"\nauthor: \"Your Name\"\ncategories: [\"Research\", \"AI/ML\"]\n---"
  },
  {
    "objectID": "contributing.html#content-guidelines",
    "href": "contributing.html#content-guidelines",
    "title": "Contributing to MIRA Data Catalog",
    "section": "",
    "text": "When contributing datasets, please include:\n\nClear description of what the dataset contains\nSize and scale information\nLanguage(s) covered\nTask(s) the dataset is designed for\nQuality metrics if available\nUsage examples or code snippets\nCitation information if applicable\nLicense information\n\n\n\n\nWhen contributing architectures, please include:\n\nArchitecture overview and key components\nModel size and parameters\nTraining details if applicable\nPerformance metrics if available\nUse cases and applications\nImplementation details\nCitation information\n\n\n\n\nFor blog posts, please ensure:\n\nClear, engaging writing\nTechnical accuracy\nProper citations and references\nCode examples where relevant\nVisual elements (plots, diagrams) when helpful\nConsistent formatting"
  },
  {
    "objectID": "contributing.html#file-organization",
    "href": "contributing.html#file-organization",
    "title": "Contributing to MIRA Data Catalog",
    "section": "",
    "text": "Dataset files: Use descriptive names like dataset-name.qmd\nArchitecture files: Use descriptive names like architecture-name.qmd\nBlog posts: Use descriptive directory names like post-title/\n\n\n\n\ndatasets/\n├── indic/\n│   ├── your-indic-dataset.qmd\n│   └── another-indic-dataset.qmd\n├── web/\n│   └── your-web-dataset.qmd\n├── benchmarks/\n│   └── your-benchmark-dataset.qmd\n└── specialized/\n    └── your-specialized-dataset.qmd\n\narchitectures/\n├── language-models/\n│   └── your-language-model.qmd\n├── multimodal/\n│   └── your-multimodal-model.qmd\n└── specialized/\n    └── your-specialized-architecture.qmd\n\nposts/\n└── your-blog-post/\n    └── index.qmd"
  },
  {
    "objectID": "contributing.html#review-process",
    "href": "contributing.html#review-process",
    "title": "Contributing to MIRA Data Catalog",
    "section": "",
    "text": "Submit your contribution by creating the appropriate files\nOur team will review the content for:\n\nTechnical accuracy\nCompleteness of documentation\nAdherence to guidelines\nQuality and usefulness\n\nFeedback will be provided if revisions are needed\nApproved contributions will be integrated into the catalog"
  },
  {
    "objectID": "contributing.html#questions",
    "href": "contributing.html#questions",
    "title": "Contributing to MIRA Data Catalog",
    "section": "",
    "text": "If you have questions about contributing, please:\n\nCheck existing content for examples\nReview the file structure to understand organization\nContact the maintainers if you need clarification"
  },
  {
    "objectID": "contributing.html#thank-you",
    "href": "contributing.html#thank-you",
    "title": "Contributing to MIRA Data Catalog",
    "section": "",
    "text": "We appreciate your contributions to the MIRA Data Catalog. Your efforts help build a comprehensive resource for the AI/ML community!"
  },
  {
    "objectID": "datasets/specialized/index.html",
    "href": "datasets/specialized/index.html",
    "title": "Specialized Datasets",
    "section": "",
    "text": "No matching items",
    "crumbs": [
      "Datasets",
      "Specialized"
    ]
  },
  {
    "objectID": "datasets/benchmarks/index.html",
    "href": "datasets/benchmarks/index.html",
    "title": "Benchmark Datasets",
    "section": "",
    "text": "No matching items",
    "crumbs": [
      "Datasets",
      "Benchmarks"
    ]
  },
  {
    "objectID": "architectures/index.html",
    "href": "architectures/index.html",
    "title": "Architecture Registry",
    "section": "",
    "text": "Language Models\n\n\nArchitectures for language modeling including encoder-only, decoder-only, and encoder-decoder models\n\n\n\n\n\n\n\n\n\n\nMultimodal Models\n\n\nArchitectures for processing multiple modalities including vision-language, audio-visual, and cross-modal models\n\n\n\n\n\n\n\n\n\n\nSpecialized Architectures\n\n\nSpecialized model architectures for specific domains including RAG and domain-specific applications\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "architectures/language-models/index.html",
    "href": "architectures/language-models/index.html",
    "title": "Language Models",
    "section": "",
    "text": "No matching items",
    "crumbs": [
      "Datasets",
      "Architectures",
      "Language Models"
    ]
  },
  {
    "objectID": "DEPLOYMENT.html",
    "href": "DEPLOYMENT.html",
    "title": "Deployment Guide",
    "section": "",
    "text": "This guide explains how to deploy the MIRA Resource Catalog website to GitHub Pages using Quarto’s built-in publishing command.\n \n\n\nThe website can be deployed with a single command using Quarto’s built-in publish functionality.\n\n\nquarto publish gh-pages\nThat’s it! The command will: - ✅ Build the website - ✅ Create/update the gh-pages branch - ✅ Deploy to GitHub Pages - ✅ Configure everything automatically\n\n\n\n\nMake your changes to the website files\nCommit your changes:\ngit add .\ngit commit -m \"Your commit message\"\ngit push origin main\nDeploy to GitHub Pages:\nquarto publish gh-pages\nAccess your site:\n\n🌐 Live URL: https://mira-iitjmu.github.io/the-registry/\n⏱️ Deployment time: Usually 2-3 minutes\n🔄 Auto-updates: Every time you run the publish command\n\n\n\n\n\n\n\n\n# Preview the website locally (recommended for development)\nquarto preview\n\n# Build the website for testing\nquarto render\n\n# Use the build script for automated building\n./scripts/build.sh\n\n\n\n\nGo to repository Settings → Pages\nUnder Source, select Deploy from a branch\nSelect gh-pages branch and / (root) folder\nSave the settings\n\nNote: This is only needed once. After the initial setup, quarto publish gh-pages handles everything automatically.\n\n\n\n\nBefore deploying, ensure:\n\nAll changes are committed to the main branch\nQuarto files (.qmd) have valid syntax\nAll referenced files exist and are accessible\nImages and assets are properly linked\nNo broken links in the content\n\n\n\n# Check Quarto configuration\nquarto check\n\n# Test local build\nquarto render\n\n# Preview locally\nquarto preview\n\n\n\n\n\n\n\nBuild Failures:\n\nCheck for syntax errors in .qmd files\nEnsure all referenced files exist\nVerify Quarto configuration in _quarto.yml\nCheck for missing dependencies\n\nSite Not Updating:\n\nVerify GitHub Pages settings are correct\nEnsure gh-pages branch exists and is up to date\nWait a few minutes for GitHub Pages to propagate changes\nClear browser cache and try again\n\nMissing Content:\n\nEnsure all files are committed to the repository\nCheck that paths in navigation are correct\nVerify file permissions and case sensitivity\nCheck for typos in file names and paths\n\nDeployment Issues:\n\nEnsure you have push permissions to the repository\nCheck if the gh-pages branch exists\nVerify Quarto is properly installed\nCheck for network connectivity issues\n\n\n\n\n\n# Check Quarto installation and configuration\nquarto check\n\n# Test local build with debug info\nquarto render --debug\n\n# Preview locally with verbose output\nquarto preview --debug\n\n# Check for broken links\nquarto render --validate-links\n\n# Verify GitHub Pages branch\ngit branch -a | grep gh-pages\n\n\n\nIf you encounter issues:\n\nCheck the logs: Look for error messages in the terminal output\nVerify setup: Ensure GitHub Pages is properly configured\nTest locally: Use quarto preview to test changes before deploying\nCheck documentation: Review Quarto documentation\nOpen an issue: Create an issue in the repository with error details\n\n\n\n\n\n\n\n\nRepository: mira-iitjmu/the-registry\nSource Branch: gh-pages (auto-managed by Quarto)\nSource Folder: / (root)\nCustom Domain: (Optional)\n\n\n\n\nThe site is configured in _quarto.yml: - Output Directory: _site - Theme: Cosmo (Bootswatch) - GitHub Integration: Enabled - Search: Enabled - Navigation: Docked sidebar\n\n\n\n\nThe quarto publish gh-pages command automatically:\n\n🔨 Render: Builds the website using Quarto\n🌿 Create Branch: Creates or updates the gh-pages branch\n🚀 Deploy: Pushes the built site to GitHub Pages\n⚙️ Configure: Sets up the necessary GitHub Pages configuration\n✅ Verify: Ensures the deployment is successful\n\n\n\n\n\n\n\nUse quarto preview for local development\nTest changes locally before deploying\nCommit changes to main branch before publishing\n\n\n\n\n\nRun quarto publish gh-pages after making changes\nCheck the live site after deployment\nMonitor for any issues or broken links\n\n\n\n\n\nRegularly update dependencies\nKeep content fresh and relevant\nMonitor site performance and accessibility\n\n\n\n\n\n\n\n\nQuarto Documentation\nGitHub Pages Documentation\nBootswatch Themes\n\n\n\n\n\nRepository Issues: GitHub Issues\nQuarto Community: Quarto Discussions\nMIRA Research Team: Contact for project-specific questions\n\n\n\n\n\n🔗 Website URL: https://mira-iitjmu.github.io/the-registry/\nThe website is automatically updated whenever you run quarto publish gh-pages. Changes typically appear within 2-3 minutes of deployment."
  },
  {
    "objectID": "DEPLOYMENT.html#quick-deployment",
    "href": "DEPLOYMENT.html#quick-deployment",
    "title": "Deployment Guide",
    "section": "",
    "text": "The website can be deployed with a single command using Quarto’s built-in publish functionality.\n\n\nquarto publish gh-pages\nThat’s it! The command will: - ✅ Build the website - ✅ Create/update the gh-pages branch - ✅ Deploy to GitHub Pages - ✅ Configure everything automatically\n\n\n\n\nMake your changes to the website files\nCommit your changes:\ngit add .\ngit commit -m \"Your commit message\"\ngit push origin main\nDeploy to GitHub Pages:\nquarto publish gh-pages\nAccess your site:\n\n🌐 Live URL: https://mira-iitjmu.github.io/the-registry/\n⏱️ Deployment time: Usually 2-3 minutes\n🔄 Auto-updates: Every time you run the publish command"
  },
  {
    "objectID": "DEPLOYMENT.html#development-workflow",
    "href": "DEPLOYMENT.html#development-workflow",
    "title": "Deployment Guide",
    "section": "",
    "text": "# Preview the website locally (recommended for development)\nquarto preview\n\n# Build the website for testing\nquarto render\n\n# Use the build script for automated building\n./scripts/build.sh\n\n\n\n\nGo to repository Settings → Pages\nUnder Source, select Deploy from a branch\nSelect gh-pages branch and / (root) folder\nSave the settings\n\nNote: This is only needed once. After the initial setup, quarto publish gh-pages handles everything automatically."
  },
  {
    "objectID": "DEPLOYMENT.html#deployment-checklist",
    "href": "DEPLOYMENT.html#deployment-checklist",
    "title": "Deployment Guide",
    "section": "",
    "text": "Before deploying, ensure:\n\nAll changes are committed to the main branch\nQuarto files (.qmd) have valid syntax\nAll referenced files exist and are accessible\nImages and assets are properly linked\nNo broken links in the content\n\n\n\n# Check Quarto configuration\nquarto check\n\n# Test local build\nquarto render\n\n# Preview locally\nquarto preview"
  },
  {
    "objectID": "DEPLOYMENT.html#troubleshooting",
    "href": "DEPLOYMENT.html#troubleshooting",
    "title": "Deployment Guide",
    "section": "",
    "text": "Build Failures:\n\nCheck for syntax errors in .qmd files\nEnsure all referenced files exist\nVerify Quarto configuration in _quarto.yml\nCheck for missing dependencies\n\nSite Not Updating:\n\nVerify GitHub Pages settings are correct\nEnsure gh-pages branch exists and is up to date\nWait a few minutes for GitHub Pages to propagate changes\nClear browser cache and try again\n\nMissing Content:\n\nEnsure all files are committed to the repository\nCheck that paths in navigation are correct\nVerify file permissions and case sensitivity\nCheck for typos in file names and paths\n\nDeployment Issues:\n\nEnsure you have push permissions to the repository\nCheck if the gh-pages branch exists\nVerify Quarto is properly installed\nCheck for network connectivity issues\n\n\n\n\n\n# Check Quarto installation and configuration\nquarto check\n\n# Test local build with debug info\nquarto render --debug\n\n# Preview locally with verbose output\nquarto preview --debug\n\n# Check for broken links\nquarto render --validate-links\n\n# Verify GitHub Pages branch\ngit branch -a | grep gh-pages\n\n\n\nIf you encounter issues:\n\nCheck the logs: Look for error messages in the terminal output\nVerify setup: Ensure GitHub Pages is properly configured\nTest locally: Use quarto preview to test changes before deploying\nCheck documentation: Review Quarto documentation\nOpen an issue: Create an issue in the repository with error details"
  },
  {
    "objectID": "DEPLOYMENT.html#configuration",
    "href": "DEPLOYMENT.html#configuration",
    "title": "Deployment Guide",
    "section": "",
    "text": "Repository: mira-iitjmu/the-registry\nSource Branch: gh-pages (auto-managed by Quarto)\nSource Folder: / (root)\nCustom Domain: (Optional)\n\n\n\n\nThe site is configured in _quarto.yml: - Output Directory: _site - Theme: Cosmo (Bootswatch) - GitHub Integration: Enabled - Search: Enabled - Navigation: Docked sidebar"
  },
  {
    "objectID": "DEPLOYMENT.html#deployment-process",
    "href": "DEPLOYMENT.html#deployment-process",
    "title": "Deployment Guide",
    "section": "",
    "text": "The quarto publish gh-pages command automatically:\n\n🔨 Render: Builds the website using Quarto\n🌿 Create Branch: Creates or updates the gh-pages branch\n🚀 Deploy: Pushes the built site to GitHub Pages\n⚙️ Configure: Sets up the necessary GitHub Pages configuration\n✅ Verify: Ensures the deployment is successful"
  },
  {
    "objectID": "DEPLOYMENT.html#best-practices",
    "href": "DEPLOYMENT.html#best-practices",
    "title": "Deployment Guide",
    "section": "",
    "text": "Use quarto preview for local development\nTest changes locally before deploying\nCommit changes to main branch before publishing\n\n\n\n\n\nRun quarto publish gh-pages after making changes\nCheck the live site after deployment\nMonitor for any issues or broken links\n\n\n\n\n\nRegularly update dependencies\nKeep content fresh and relevant\nMonitor site performance and accessibility"
  },
  {
    "objectID": "DEPLOYMENT.html#support-resources",
    "href": "DEPLOYMENT.html#support-resources",
    "title": "Deployment Guide",
    "section": "",
    "text": "Quarto Documentation\nGitHub Pages Documentation\nBootswatch Themes\n\n\n\n\n\nRepository Issues: GitHub Issues\nQuarto Community: Quarto Discussions\nMIRA Research Team: Contact for project-specific questions"
  },
  {
    "objectID": "DEPLOYMENT.html#live-site",
    "href": "DEPLOYMENT.html#live-site",
    "title": "Deployment Guide",
    "section": "",
    "text": "🔗 Website URL: https://mira-iitjmu.github.io/the-registry/\nThe website is automatically updated whenever you run quarto publish gh-pages. Changes typically appear within 2-3 minutes of deployment."
  }
]